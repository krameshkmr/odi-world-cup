library(tidyverse)
library(knitr)
library(tinytex)
library(cricketdata)
library(leaps)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = "60%")
#knitr::opts_chunk$set(fig.align = "center")
odi <- read.csv("~/Downloads/odi.csv")
odi$date <- as.Date(odi$date)
odi$date <- format(odi$date, "%Y")
odi <- rename(odi, year = date)
odi %>% ggplot(aes(x = mov)) +
geom_boxplot(fill = "skyblue", color = "black") +
labs(x = "Margin of Victory") +
theme_bw()
summary(odi$mov)
which(odi$mov == -0.8400)
odi %>% ggplot(aes(x = mov)) +
geom_boxplot(fill = "skyblue", color = "black") +
labs(x = "Margin of Victory") +
theme_bw()
summary(odi$mov)
library(tidyverse)
library(knitr)
library(tinytex)
library(cricketdata)
library(leaps)
round(cor(odi[, 6:20]), 2)
round(cor(odi[, 6:20]), 2)
knitr::include_graphics("~/Desktop/cor.png")
knitr::include_graphics("~/Desktop/cor.png")
knitr::include_graphics("~/Desktop/cor.png")
library(tidyverse)
library(knitr)
library(tinytex)
library(cricketdata)
library(leaps)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = "60%")
odi %>% pairs()
odi[, 6:20] %>% pairs()
View(odi)
odi[, 6:15] %>% pairs()
odi[, 16:20] %>% pairs()
odi[, 6:20] %>% select(-c("bowlers_used", "pct_mdns", "wkts", "econ")) %>%
pairs()
odi[, 6:20] %>% select(-c("bowlers_used", "pct_mdns", "wkts", "econ")) %>%
pairs()
odi[, 6:20] %>% select(c("to_runs_pct", "mo_runs_pct", "to_mins_pct", "mo_mins_pct", "to_bf_pct", "mo_bf_pct", "mov")) %>% pairs()
#odi[, 6:20] %>% select(-c("bowlers_used", "pct_mdns", "wkts", "econ")) %>%
#pairs()
library(tidyverse)
library(knitr)
library(tinytex)
library(cricketdata)
library(leaps)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = "60%")
odi <- read.csv("~/Downloads/odi.csv")
odi$date <- as.Date(odi$date)
odi$date <- format(odi$date, "%Y")
odi <- rename(odi, year = date)
odi %>% ggplot(aes(x = mov)) +
geom_boxplot(fill = "skyblue", color = "black") +
labs(x = "Margin of Victory") +
theme_bw()
summary(odi$mov)
odi[, 6:20] %>% select(c("to_runs_pct", "mo_runs_pct", "to_mins_pct", "mo_mins_pct", "to_bf_pct", "mo_bf_pct", "mov")) %>% pairs()
odi[, 6:20] %>% select(c("pct_4s", "pct_6s", "to_sr", "mo_sr", "mov")) %>% pairs()
odi[, 16:20] %>% pairs()
knitr::include_graphics("~/Desktop/cor.png")
train_set <- odi %>% filter(year %in% c(2003, 2007, 2011, 2015))
train_set <- train_set[, 6:20]
test_set <- odi %>% filter(year == 2019)
test_set <- test_set[, 6:20]
model_1 <- lm(mov~., data=train_set)
summary(model_1)
predictions <- predict(model_1, test_set)
rmse <- sqrt(mean((test_set$mov - predictions)^2))
rmse
rmse / (max(test_set$mov) - min(test_set$mov))
install.packages("car")
library(tidyverse)
library(knitr)
library(tinytex)
library(cricketdata)
library(leaps)
library(car)
library(tidyverse)
library(knitr)
library(tinytex)
library(cricketdata)
library(leaps)
library(car)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = "60%")
odi <- read.csv("~/Downloads/odi.csv")
odi$date <- as.Date(odi$date)
odi$date <- format(odi$date, "%Y")
odi <- rename(odi, year = date)
odi %>% ggplot(aes(x = mov)) +
geom_boxplot(fill = "skyblue", color = "black") +
labs(x = "Margin of Victory") +
theme_bw()
summary(odi$mov)
odi[, 6:20] %>% select(c("to_runs_pct", "mo_runs_pct", "to_mins_pct", "mo_mins_pct", "to_bf_pct", "mo_bf_pct", "mov")) %>% pairs()
odi[, 6:20] %>% select(c("pct_4s", "pct_6s", "to_sr", "mo_sr", "mov")) %>% pairs()
odi[, 16:20] %>% pairs()
knitr::include_graphics("~/Documents/GitHub/odi-world-cup/cor.png")
train_set <- odi %>% filter(year %in% c(2003, 2007, 2011, 2015))
train_set <- train_set[, 6:20]
test_set <- odi %>% filter(year == 2019)
test_set <- test_set[, 6:20]
model_1 <- lm(mov~., data=train_set)
summary(model_1)
predictions <- predict(model_1, test_set)
rmse <- sqrt(mean((test_set$mov - predictions)^2))
rmse
rmse / (max(test_set$mov) - min(test_set$mov))
avPlots(model_1, layout = c(3,5))
#create empty vector to hold accuracies
rmse_1 <- data.frame(vals=rep(NA,14))
for (i in 1:14) {
#remove i-th variable
train_min1 <- train_set[,-i]
#fit model minus one variable
model_min1 <- lm(mov~.,data=train_min1)
#classify testing observations
test_min1 <- test_set %>%
mutate(preds=predict(model_min1,newdata=test_set))
#compute and save overall accuracy
rmse_1$vals[i] <- sqrt(mean((test_set$mov - test_min1$preds)^2))
}
rmse_1
#permanently remove one variable
train_min1 <- train_set[,-10]
#create empty vector to hold accuracies
rmse_2 <- data.frame(vals=rep(NA,13))
for (i in 1:13) {
#remove i-th variable
train_min2 <- train_min1[,-i]
#fit model minus one variable
model_min2 <- lm(mov~.,data=train_min2)
#classify testing observations
test_min2 <- test_set %>%
mutate(preds=predict(model_min2,newdata=test_set))
#compute and save overall accuracy
rmse_2$vals[i] <- sqrt(mean((test_set$mov - test_min2$preds)^2))
}
rmse_2
#permanently remove one variable
train_min2 <- train_min1[,-10]
#create empty vector to hold accuracies
rmse_3 <- data.frame(vals=rep(NA,12))
for (i in 1:12) {
#remove i-th variable
train_min3 <- train_min2[,-i]
#fit model minus one variable
model_min3 <- lm(mov~.,data=train_min3)
#classify testing observations
test_min3 <- test_set %>%
mutate(preds=predict(model_min3,newdata=test_set))
#compute and save overall accuracy
rmse_3$vals[i] <- sqrt(mean((test_set$mov - test_min3$preds)^2))
}
rmse_3
#permanently remove one variable
train_min3 <- train_min2[,-5]
#create empty vector to hold accuracies
rmse_4 <- data.frame(vals=rep(NA,11))
for (i in 1:11) {
#remove i-th variable
train_min4 <- train_min3[,-i]
#fit model minus one variable
model_min4 <- lm(mov~.,data=train_min4)
#classify testing observations
test_min4 <- test_set %>%
mutate(preds=predict(model_min4,newdata=test_set))
#compute and save overall accuracy
rmse_4$vals[i] <- sqrt(mean((test_set$mov - test_min4$preds)^2))
}
rmse_4
#permanently remove one variable
train_min4 <- train_min3[,-7]
#create empty vector to hold accuracies
rmse_5 <- data.frame(vals=rep(NA,10))
for (i in 1:10) {
#remove i-th variable
train_min5 <- train_min4[,-i]
#fit model minus one variable
model_min5 <- lm(mov~.,data=train_min5)
#classify testing observations
test_min5 <- test_set %>%
mutate(preds=predict(model_min5,newdata=test_set))
#compute and save overall accuracy
rmse_5$vals[i] <- sqrt(mean((test_set$mov - test_min5$preds)^2))
}
rmse_5
#permanently remove one variable
train_min5 <- train_min4[,-4]
#create empty vector to hold accuracies
rmse_6 <- data.frame(vals=rep(NA,9))
for (i in 1:9) {
#remove i-th variable
train_min6 <- train_min5[,-i]
#fit model minus one variable
model_min6 <- lm(mov~.,data=train_min6)
#classify testing observations
test_min6 <- test_set %>%
mutate(preds=predict(model_min6,newdata=test_set))
#compute and save overall accuracy
rmse_6$vals[i] <- sqrt(mean((test_set$mov - test_min6$preds)^2))
}
rmse_6
model_odi <- lm(mov~., data=train_min5)
summary(model_odi)
predictions <- predict(model_odi, test_set)
rmse <- sqrt(mean((test_set$mov - predictions)^2))
rmse / (max(odi$mov) - min(odi$mov))
avPlots(model_odi, layout = c(3,3))
final_set <- odi %>% select(to_runs_pct, mo_runs_pct, to_mins_pct, mo_bf_pct, pct_4s, to_sr, pct_mdns, wkts, econ, mov)
predictions <- predict(model_odi, final_set)
rmse <- sqrt(mean((final_set$mov - predictions)^2))
nrmse <- rmse / (max(odi$mov) - min(odi$mov))
resids <- final_set$mov - predictions
as.data.frame(predictions) %>%
ggplot(aes(predictions, resids)) +
geom_point() +
geom_hline(yintercept = 0, color="red")
resids <- final_set$mov - predictions
as.data.frame(predictions) %>%
ggplot(aes(predictions, resids)) +
geom_point() +
geom_hline(yintercept = 0, color="red")
# Take a random game and predict mov
sample(odi, 1)
# Take a random game and predict mov
sample(odi, size = 1, replace = F)
?sample
# Take a random game and predict mov
odi[1:nrows(odi), 1]
# Take a random game and predict mov
odi[1:nrows(odi), 1,]
# Take a random game and predict mov
odi[1:nrow(odi), 1,]
# Take a random game and predict mov
odi[sample(1:nrow(odi), 1), ]
# Take a random game and predict mov
match_rand <- odi[sample(1:nrow(odi), 1), ]
predict(model_odi, match_rand)
# Take a random game and predict mov
match_rand <- odi[sample(1:nrow(odi), 1), ]
match_rand$mov
predict(model_odi, match_rand)
predict(model_odi, match_rand) - match_rand$mov
# Take a random game and predict mov
match_rand <- odi[sample(1:nrow(odi), 1), ]
match_rand$mov
predict(model_odi, match_rand)
#predict(model_odi, match_rand) - match_rand$mov
# Take a random game and predict mov
match_rand <- odi[sample(1:nrow(odi), 1), ]
match_rand$mov
predict(model_odi, match_rand)
#predict(model_odi, match_rand) - match_rand$mov
# Take a random game and predict mov
set.seed(1)
match_rand <- odi[sample(1:nrow(odi), 1), ]
match_rand$mov
predict(model_odi, match_rand)
#predict(model_odi, match_rand) - match_rand$mov
# Take a random game and predict mov
set.seed(1)
match_rand <- odi[sample(1:nrow(odi), 1), ]
match_rand$mov
predict(model_odi, match_rand)
#predict(model_odi, match_rand) - match_rand$mov
View(model_1)
View(match_rand)
# Take a random game and predict mov
set.seed(1)
match_rand <- odi[sample(1:nrow(odi), 1), ]
match_rand$mov
predict(model_odi, match_rand)
predict(model_odi, match_rand) - match_rand$mov
library(tidyverse)
library(knitr)
library(tinytex)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = "60%",fig.align='center')
#import and wrangle data
pumpkin <- read.csv('/Users/sriharisrinivasan/Desktop/STAT 3400 - Applied Regression/Datasets/pumpkin_data.csv') %>%
mutate(TypeA=ifelse(Type=='A',1,0)) %>%
select(-Type,-Major_Axis_Length,-Eccentricity)
#set a randomization seed for repeatability
set.seed(303)
#randomly select 75% of the rows for training
rows <- sample(x=nrow(pumpkin),size=floor(0.75*nrow(pumpkin)),replace=FALSE)
#split data into the two groups
training <- pumpkin[rows,]
testing <- pumpkin[-rows,]
#fit model to training data
model <- glm(TypeA~.,data=training,family='binomial')
#classify observations in testing set
testing_class <- testing %>%
mutate(Type_prob=predict(model,newdata=testing,type='response'),
Type_class=if_else(Type_prob>0.5,1,0))
#create contingency table
table(testing_class$TypeA,testing_class$Type_class)
#load ROCR package
library(ROCR)
#create required objects for ROC
pred <- prediction(predictions=testing_class$Type_prob,
labels=testing_class$TypeA)
perf <- performance(pred,measure='sens',x.measure='spec')
#plot ROC curve with threshold color
plot(perf,colorize=TRUE)
#classify observations in testing set
testing_class <- testing %>%
mutate(Type_prob=predict(model,newdata=testing,type='response'),
Type_class=if_else(Type_prob>0.485,1,0))
#create contingency table
table(testing_class$TypeA,testing_class$Type_class)
#classify observations in testing set
testing_class <- testing %>%
mutate(Type_prob=predict(model,newdata=testing,type='response'),
Type_class=if_else(Type_prob>0.515,1,0))
#create contingency table
table(testing_class$TypeA,testing_class$Type_class)
#plot accuracy curve
perf2 <- performance(pred,measure='acc')
plot(perf2)
View(perf2)
#plot TPR vs. FPR curve
perf3 <- performance(pred,measure='tpr',x.measure='fpr')
plot(perf3,colorize=TRUE)
abline(a=0,b=1)
#compute AUC for the ROC curve
perf4 <- performance(pred,measure='auc')
perf4@y.values
